{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import signal\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import fftpack\n",
    "from scipy.fftpack import fft,ifft\n",
    "from scipy.signal import freqs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Read video with OpenCV.\n",
    "cap=cv2.VideoCapture('/home/johnson/Desktop/UPDRS/UPDRS_video/Tim_Tremor/t014_crop_256_10s.mp4')\n",
    "# Read sensor data\n",
    "tsv_data = pd.read_csv('/home/johnson/tremor_dataset/T014_Right/Rest/kinect_accelerometer.tsv', sep='\\t') \n",
    "\n",
    "## Get video info\n",
    "RES = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "#create video writer to write detected_video\n",
    "#output_video = \"../UPDRS_result/t014_tremor.mp4\"\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "#out = cv2.VideoWriter(output_video, fourcc, 30, RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single hand (grasp)\n",
    "hands = mp_hands.Hands(static_image_mode=True,max_num_hands=2,min_detection_confidence=0.7)\n",
    "\n",
    "record = []\n",
    "frame_count = 0\n",
    "img_list = []\n",
    "lost_frame = []\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        frame = frame[:,:]\n",
    "        frame_count += 1\n",
    "\n",
    "        # Convert the BGR image to RGB, flip the image around y-axis for correct \n",
    "        # handedness output and process it with MediaPipe Hands.\n",
    "        results = hands.process(cv2.flip(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), 1))\n",
    "        annotated_image = cv2.flip(frame.copy(), 1)\n",
    "\n",
    "        if results.multi_hand_landmarks != None:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                #middle_y = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x\n",
    "                record.append(hand_landmarks.landmark)\n",
    "\n",
    "        else:\n",
    "            lost_frame.append(frame_count)\n",
    "\n",
    "        #after processing the hand, flip back the image\n",
    "        annotated_image = cv2.flip(annotated_image, 1)\n",
    "        img_list.append(annotated_image)\n",
    "        #out.write(annotated_image)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "#out.release()\n",
    "#plt.plot(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_x = tsv_data[\"-326\"][0:10000] - np.mean(tsv_data[\"-326\"][0:10000])\n",
    "sensor_x = np.array(sensor_x)\n",
    "plt.plot(sensor_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = img_list[0].copy()\n",
    "plt.imshow(cv2.cvtColor(copy, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(21):\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    x = [i[index].x for i in record]\n",
    "    y = [i[index].y for i in record]\n",
    "    ax1.plot(x) ; ax1.title.set_text(f'{index} (x-axis)')\n",
    "    ax2.plot(y) ; ax2.title.set_text(f'{index} (y-axis)')\n",
    "    fig.tight_layout()\n",
    "#a = [i[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y for i in record]\n",
    "#plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_frequency(frequency,amplitude):\n",
    "    freqs = []\n",
    "    amps = []\n",
    "    for freq,amp in zip(frequency,amplitude):\n",
    "        if 0<=freq<=14:\n",
    "            freqs.append(freq)\n",
    "            amps.append(abs(amp))\n",
    "    print(frequency[np.argmax(np.abs(amplitude))])\n",
    "    plt.plot(freqs,amps)\n",
    "\n",
    "def draw_video_frequency(frequency_x,amplitude_x,frequency_y,amplitude_y,index):\n",
    "    freqs_x = []\n",
    "    amps_x = []\n",
    "    freqs_y = []\n",
    "    amps_y = []\n",
    "\n",
    "    for freq,amp in zip(frequency_x,amplitude_x):\n",
    "        if 0<=freq<=14:\n",
    "            freqs_x.append(freq)\n",
    "            amps_x.append(abs(amp))\n",
    "    for freq,amp in zip(frequency_y,amplitude_y):\n",
    "        if 0<=freq<=14:\n",
    "            freqs_y.append(freq)\n",
    "            amps_y.append(abs(amp))\n",
    "\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    ax1.plot(freqs_x,amps_x) ; ax1.title.set_text(str(index) + \" (x-axis)\")\n",
    "    ax2.plot(freqs_y,amps_y) ; ax2.title.set_text(str(index) + \" (y-axis)\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "def find_frequency(frequency,amplitude):\n",
    "    amp_sort = sorted(amplitude,reverse=True)\n",
    "    maximum = amp_sort[0]\n",
    "    domain_frequency = frequency[np.argmax(amplitude)]\n",
    "    if 3 <= domain_frequency <= 8:\n",
    "        return domain_frequency\n",
    "\n",
    "    for amp in amp_sort:\n",
    "        if(maximum * 0.4 <= amp):\n",
    "            index = np.where(amplitude == amp)\n",
    "            freq = frequency[index]\n",
    "            if(3<= freq <= 8):\n",
    "                return freq[0]\n",
    "\n",
    "        else:\n",
    "            return domain_frequency\n",
    "\n",
    "\n",
    "sensor_X = fftpack.fft(sensor_x)\n",
    "sensor_freqs = fftpack.fftfreq(len(sensor_x)) * 1000\n",
    "draw_frequency(sensor_freqs,sensor_X)\n",
    "\n",
    "for index in range(21):\n",
    "    x = [i[index].x for i in record]\n",
    "    x = np.array(x)\n",
    "    x = x - np.mean(x)\n",
    "\n",
    "    y = [i[index].y for i in record]\n",
    "    y = np.array(y)\n",
    "    y = y - np.mean(y)\n",
    "\n",
    "    X = fftpack.fft(x)\n",
    "    x_freqs = fftpack.fftfreq(len(x)) * 30 #(len(a)/len(img_list))*30\n",
    "    freq_x = find_frequency(x_freqs[:int(x_freqs.size/2)],np.abs(X[:int(X.size/2)]))\n",
    "\n",
    "    Y = fftpack.fft(y)\n",
    "    y_freqs = fftpack.fftfreq(len(y)) * 30 #(len(a)/len(img_list))*30\n",
    "    freq_y = find_frequency(y_freqs[:int(y_freqs.size/2)],np.abs(Y[:int(Y.size/2)]))\n",
    "    #print(f'{index:3}. {x_freqs[np.argmax(np.abs(X))]:.4f}, {y_freqs[np.argmax(np.abs(Y))]:.4f}')\n",
    "    print(f'{index:3}. {freq_x:.4f}, {freq_y:.4f}')\n",
    "    \n",
    "    draw_video_frequency(x_freqs,np.abs(X),y_freqs,np.abs(Y),index)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = (min(a) + max(a))/2\n",
    "pro = (max(a) - mid)\n",
    "\n",
    "peaks, _ = signal.find_peaks(a,height=mid,prominence=pro)\n",
    "valley, _ = signal.find_peaks(np.array(a)*-1,height=mid*-1)\n",
    "\n",
    "plt.plot(a)\n",
    "plt.plot(peaks,np.array(a)[peaks],\"x\")\n",
    "plt.plot(valley,np.array(a)[valley],\"o\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f35382d907cb9c24a78f87fdb40cfd6f3acc0f7e4b3752e533ecdd62cd27e97f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('py3.9': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
