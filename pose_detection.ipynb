{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Read video with OpenCV.\n",
    "cap=cv2.VideoCapture('../UPDRS_video/arise from chair.mp4')\n",
    "\n",
    "## Get video info\n",
    "RES=(round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "#create video writer to write detected_video\n",
    "output_video = \"../UPDRS_result/result.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle(vector_1,vector_2):\n",
    "    unit_vector_1 = vector_1 / np.linalg.norm(vector_1)\n",
    "    unit_vector_2 = vector_2 / np.linalg.norm(vector_2)\n",
    "    dot_product = np.dot(unit_vector_1, unit_vector_2)\n",
    "    angle = np.arccos(dot_product)\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leg_agility detector\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=True,min_detection_confidence=0.4)\n",
    "\n",
    "right_foot_index = []\n",
    "left_foot_index = []\n",
    "ankle_dis = []\n",
    "frame_count = 0\n",
    "lost_frame = []\n",
    "img_list = []\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        annotated_image = frame.copy()\n",
    "\n",
    "        if results.pose_landmarks != None:\n",
    "            mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            right_foot_index.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX].y)\n",
    "            left_foot_index.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].y)\n",
    "\n",
    "            img_list.append(annotated_image)\n",
    "        else:\n",
    "            lost_frame.append(frame_count)\n",
    "\n",
    "        frame_count += 1\n",
    "        out.write(annotated_image)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arise from chair\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=True,min_detection_confidence=0.4)\n",
    "\n",
    "right_shoulder = []\n",
    "left_shoulder = []\n",
    "frame_count = 0\n",
    "lost_frame = []\n",
    "img_list = []\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        annotated_image = frame.copy()\n",
    "\n",
    "        if results.pose_landmarks != None:\n",
    "            mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            right_shoulder.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y)\n",
    "            left_shoulder.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y)\n",
    "\n",
    "        else:\n",
    "            lost_frame.append(frame_count)\n",
    "\n",
    "        img_list.append(annotated_image)\n",
    "        frame_count += 1\n",
    "        out.write(annotated_image)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(right_shoulder); axs[0].title.set_text(\"right shoulder\")\n",
    "axs[1].plot(left_shoulder) ; axs[1].title.set_text(\"left shoulder\")\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"UPDRS_result/pronation/patient_wave.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single person\n",
    "pose = mp_pose.Pose(static_image_mode=True,min_detection_confidence=0.4)\n",
    "\n",
    "right_heel = []\n",
    "right_knee_angle = []\n",
    "ankle_dis = []\n",
    "frame_count = 0\n",
    "lost_frame = []\n",
    "img_list = []\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        annotated_image = frame.copy()\n",
    "\n",
    "        if results.pose_landmarks != None:\n",
    "            mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            right_heel.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HEEL].y)\n",
    "\n",
    "            right_hip_x = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP].x\n",
    "            right_hip_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP].y\n",
    "            right_knee_x = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE].x\n",
    "            right_knee_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE].y\n",
    "            right_ankle_x = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ANKLE].x\n",
    "            right_ankle_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ANKLE].y\n",
    "\n",
    "            left_ankle_x = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ANKLE].x\n",
    "\n",
    "            vector_a = [right_knee_x-right_hip_x, right_knee_y-right_hip_y]\n",
    "            vector_b = [right_ankle_x-right_knee_x, right_ankle_y-right_knee_y]\n",
    "\n",
    "            right_knee_angle.append(np.degrees(angle(vector_a,vector_b)))\n",
    "            ankle_dis.append(abs(right_ankle_x-left_ankle_x))\n",
    "            \n",
    "\n",
    "            img_list.append(annotated_image)\n",
    "        else:\n",
    "            lost_frame.append(frame_count)\n",
    "\n",
    "        frame_count += 1\n",
    "        #out.write(annotated_image)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "#out.release()\n",
    "plt.plot(ankle_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ankle_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"right_shoulder(y axis)\")\n",
    "plt.xlabel(\"frame\")\n",
    "plt.ylabel(\"pixel coordinate\")\n",
    "plt.plot(right_shoulder)\n",
    "plt.savefig(\"../UPDRS_result/arise/right_shoulder.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leg agility\n",
    "copy = right_foot_index[:390].copy()\n",
    "\n",
    "peaks, _ = signal.find_peaks(copy,height=0.86,prominence=0.01)\n",
    "\n",
    "plt.plot(copy)\n",
    "plt.plot(peaks,np.array(copy)[peaks],\"x\")\n",
    "\n",
    "\n",
    "#calculcate stomp action time\n",
    "action_time_list = []\n",
    "action_time_list.append(peaks[0])\n",
    "for time in np.diff(peaks):\n",
    "    action_time_list.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ankle distance\n",
    "copy = ankle_dis.copy()\n",
    "smooth = savgol_filter(copy,window_length=11,polyorder=3)\n",
    "\n",
    "peaks, _ = signal.find_peaks(smooth,height=0.08,prominence=0.03)\n",
    "\n",
    "plt.plot(smooth)\n",
    "plt.plot(peaks,np.array(smooth)[peaks],\"x\")\n",
    "\n",
    "plt.title(\"ankle distance(x axis)\")\n",
    "plt.xlabel(\"frame\")\n",
    "plt.ylabel(\"pixel coordinate\")\n",
    "plt.savefig(\"ankle_dis_peak.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = img_list[10].copy()\n",
    "plt.imshow(cv2.cvtColor(copy, cv2.COLOR_BGR2RGB))\n",
    "#plt.savefig(\"./UPDRS_gait/heelpeak10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_outliers(data):\n",
    "    # finding the 1st quartile\n",
    "    q1 = np.quantile(data, 0.25)\n",
    "    \n",
    "    # finding the 3rd quartile\n",
    "    q3 = np.quantile(data, 0.75)\n",
    "    \n",
    "    # finding the iqr region\n",
    "    iqr = q3-q1\n",
    "    \n",
    "    # finding upper and lower whiskers\n",
    "    upper_bound = q3+(15*iqr)\n",
    "    lower_bound = q1-(15*iqr)\n",
    "    print(lower_bound,upper_bound)\n",
    "\n",
    "    removed = [x for x in data if lower_bound < x < upper_bound]\n",
    "\n",
    "    return removed\n",
    "\n",
    "def reject_outliers(arr):\n",
    "    dis = np.array(arr)\n",
    "    u = np.mean(dis,axis=0)\n",
    "    s = np.std(dis,axis=0)\n",
    "    final_list = [x for x in arr if (x > u - 2*s)]\n",
    "    final_list = [x for x in final_list if (x < u + 2*s)]\n",
    "    return final_list\n",
    "\n",
    "def get_median_filtered(signal, threshold=0.1):\n",
    "    signal = signal.copy()\n",
    "    signal = np.array(signal)\n",
    "    difference = np.abs(signal - np.median(signal))\n",
    "    median_difference = np.median(difference)\n",
    "    if median_difference == 0:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = difference / float(median_difference)\n",
    "    mask = s > threshold\n",
    "    signal[mask] = np.median(signal)\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = boxplot_outliers(right_heel)\n",
    "plt.title(\"right heel\")\n",
    "plt.xlabel(\"frame\")\n",
    "plt.ylabel(\"pixel coordinate\")\n",
    "plt.plot(removed)\n",
    "plt.savefig(\"heel_removed_outlier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arise from chair\n",
    "copy = savgol_filter(right_shoulder,31,3)\n",
    "#copy = right_shoulder.copy()\n",
    "\n",
    "\n",
    "mid = (min(right_shoulder) + max(right_shoulder))/2\n",
    "pro = (max(right_shoulder) - mid)\n",
    "\n",
    "peaks, _ = signal.find_peaks(copy,height=mid,prominence=pro)\n",
    "valley, _ = signal.find_peaks(np.array(copy)*-1,height=mid*-1)\n",
    "\n",
    "start_frame = peaks[0]\n",
    "end_frame = valley[0]\n",
    "\n",
    "plt.title(\"right_shoulder\")\n",
    "plt.xlabel(\"frame\")\n",
    "plt.ylabel(\"pixel coordinate\")\n",
    "\n",
    "plt.plot(copy)\n",
    "plt.plot(peaks,np.array(copy)[peaks],\"x\")\n",
    "plt.plot(valley,np.array(copy)[valley],\"o\")\n",
    "plt.savefig(\"../UPDRS_result/arise/arise_wave.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = savgol_filter(ankle_dis,11,3)\n",
    "\n",
    "peaks, _ = signal.find_peaks(smooth,height=0.08,prominence=0.03)\n",
    "#valley, _ = signal.find_peaks(smooth*-1,height=-0.88,prominence=0.01)\n",
    "\n",
    "fist_closing_frame = peaks\n",
    "\n",
    "#calculcate fist closing action time\n",
    "action_time_list = []\n",
    "action_time_list.append(fist_closing_frame[0])\n",
    "for time in np.diff(fist_closing_frame):\n",
    "    action_time_list.append(time)\n",
    "\n",
    "plt.title(\"right heel\")\n",
    "plt.xlabel(\"frame\")\n",
    "plt.ylabel(\"pixel coordinate\")\n",
    "\n",
    "plt.plot(smooth)\n",
    "plt.plot(peaks,np.array(smooth)[peaks],\"x\")\n",
    "#plt.plot(valley,np.array(smooth)[valley],\"o\")\n",
    "#plt.savefig(\"heel_PeakValley.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write result to video (arise from chair)\n",
    "action_time = 0\n",
    "has_result = 0\n",
    "time_count = 0\n",
    "state = \"sit\"\n",
    "for i in range(len(img_list)):\n",
    "    if i not in lost_frame:\n",
    "        if has_result == start_frame:\n",
    "            state = \"arise\"\n",
    "        elif has_result == end_frame:\n",
    "            state = \"stand\"\n",
    "        has_result += 1\n",
    "    if state == \"arise\":\n",
    "        time_count+=1\n",
    "\n",
    "    cv2.putText(img_list[i],f'state:{state}',(10, 70), cv2.FONT_HERSHEY_SIMPLEX,1.5, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "    cv2.putText(img_list[i],f'action_time:{time_count/fps:.2f}s',(10, 120), cv2.FONT_HERSHEY_SIMPLEX,1.5, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "    out.write(img_list[i])\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write result to video (leg agility)\n",
    "action_count = 0\n",
    "action_time = 0\n",
    "for i in range(len(img_list)):\n",
    "    if( len(peaks) > action_count and i == peaks[action_count]):\n",
    "        action_time = action_time_list[action_count]\n",
    "        action_count += 1\n",
    "    cv2.putText(img_list[i],f'action_count:{action_count}',(10, 70), cv2.FONT_HERSHEY_SIMPLEX,1.5, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "    cv2.putText(img_list[i],f'action_time:{action_time/fps:.2f}s',(10, 120), cv2.FONT_HERSHEY_SIMPLEX,1.5, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "    out.write(img_list[i])\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write result to video (step length)\n",
    "step = 0\n",
    "step_length = 0\n",
    "for i in range(len(img_list)):\n",
    "    if( len(fist_closing_frame) > step and i == fist_closing_frame[step]):\n",
    "        step_length = ankle_dis[peaks[step]]\n",
    "        step += 1\n",
    "    cv2.putText(img_list[i],f'step:{step}',(10, 70), cv2.FONT_HERSHEY_SIMPLEX,1.5, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "    cv2.putText(img_list[i],f'step_length:{step_length:.2f}',(10, 120), cv2.FONT_HERSHEY_SIMPLEX,1.5, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "    out.write(img_list[i])\n",
    "\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f35382d907cb9c24a78f87fdb40cfd6f3acc0f7e4b3752e533ecdd62cd27e97f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('py3.9': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
